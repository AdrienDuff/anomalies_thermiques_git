{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "#%matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import tifffile as tiff\n",
    "from libtiff import TIFF\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.mixture import BayesianGaussianMixture\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "import keras\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers import Dense, Input, Conv2D, Dropout, Permute, Reshape, Flatten, GaussianNoise, MaxPooling2D, Concatenate\n",
    "from keras.models import Sequential, Model\n",
    "from keras.engine.topology import Input\n",
    "from keras.utils import plot_model\n",
    "\n",
    "\n",
    "pickle_save_path = \"../../Data/\"\n",
    "pickle_col_augmented_path = \"../../Data/col_augmented.pickle\"\n",
    "pickle_col_not_augmented_path = \"../../Data/col_not_augmented.pickle\"\n",
    "pickle_grey_augmented_path = \"../../Data/grey_augmented.pickle\"\n",
    "pickle_grey_not_augmented_path = \"../../Data/grey_not_augmented.pickle\"\n",
    "pickle_grey_augmented_binary_save_path = \"../../Data/grey_augmented_binary.pickle\"\n",
    "pickle_hough_val_save_path = \"../../Data/hough_val.pickle\"\n",
    "pickle_hog_val_save_path = \"../../Data/hog_val.pickle\"\n",
    "pickle_hes_val_save_path = \"../../Data/hes_val.pickle\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN directement sur image couleur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(pickle_col_augmented_path, 'rb') as my_pickle:\n",
    "    X, Y = pickle.load(my_pickle)\n",
    "#X_norm = normalize(X.reshape((X.shape[0],-1))) #we normalize the data\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "prob_dropout = 0.3\n",
    "model = Sequential()\n",
    "model.add(Conv2D(filters = 16, kernel_size = 3, activation ='relu', data_format = \"channels_first\", input_shape = (3,31,31)))\n",
    "model.add(Dropout(prob_dropout))\n",
    "model.add(MaxPooling2D(pool_size = (2,2), data_format = \"channels_first\"))\n",
    "model.add(Conv2D(filters = 32, kernel_size = 3, activation ='relu', data_format = \"channels_first\"))\n",
    "model.add(Dropout(prob_dropout))\n",
    "model.add(MaxPooling2D(pool_size = (2,2), data_format = \"channels_first\"))\n",
    "model.add(Conv2D(filters = 64, kernel_size = 3, activation ='relu', data_format = \"channels_first\"))\n",
    "model.add(Dropout(prob_dropout))\n",
    "model.add(MaxPooling2D(pool_size = (2,2), data_format = \"channels_first\"))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(model, to_file='../../Images/model_cnn_img_coul.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si l'apprentissage n'est pas fini --> relancer le .fit en faisant varier le nombre d'epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, Y_train,\n",
    "          epochs=15,\n",
    "          batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(X_test, Y_test)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TEST CNN sur image couleur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SIZE_IMAGETTE = 31\n",
    "RAYON_IMAGETTE = int(SIZE_IMAGETTE/2)\n",
    "\n",
    "def search_on_big_image(modele,image_path, need_preprocess = False, stride = 25, from_greyscale = False, zone = None, display_big = False, threshold = 0.5):\n",
    "  #On fait glisser une fenêtre sur toute l'image\n",
    "  imagettes_new = []\n",
    "  tif_file = TIFF.open(image_path, mode='r')\n",
    "  big_image = tif_file.read_image()\n",
    "  if zone:\n",
    "    pt1 = zone[0]\n",
    "    pt2 = zone[1]\n",
    "    if from_greyscale:\n",
    "        big_image = big_image[pt1[0]:pt2[0]+1,pt1[1]:pt2[1]+1]\n",
    "    else:\n",
    "        big_image = big_image[:,pt1[0]:pt2[0]+1,pt1[1]:pt2[1]+1]\n",
    "  big_shape = big_image.shape\n",
    "  print(\"shape big image :\",big_shape)\n",
    "  if display_big:\n",
    "    plt.ion()\n",
    "    fig = plt.figure(figsize=(18, 18))\n",
    "    ax = fig.add_subplot(111)\n",
    "    if from_greyscale:\n",
    "        ax.imshow(big_image, cmap='gray')\n",
    "        plt.show()\n",
    "    else:\n",
    "        ax.imshow(np.moveaxis(big_image,0,2))\n",
    "        fig.canvas.draw()\n",
    "  nb_test = 0\n",
    "  for xCoord in np.arange(start = SIZE_IMAGETTE, stop = big_shape[1] - SIZE_IMAGETTE, step = stride):\n",
    "      for yCoord in np.arange(start = SIZE_IMAGETTE, stop = big_shape[2] - SIZE_IMAGETTE, step = stride):\n",
    "            nb_test +=1\n",
    "            if from_greyscale:\n",
    "                test_imagette = big_image[xCoord-RAYON_IMAGETTE : xCoord+RAYON_IMAGETTE+1, yCoord-RAYON_IMAGETTE : yCoord+RAYON_IMAGETTE+1]                    \n",
    "            else:\n",
    "                test_imagette_color = big_image[:, xCoord-RAYON_IMAGETTE : xCoord+RAYON_IMAGETTE+1, yCoord-RAYON_IMAGETTE : yCoord+RAYON_IMAGETTE+1]\n",
    "                #if grey_modele:\n",
    "                #   test_imagette = RGBToGreyscale(test_imagette_color)\n",
    "                if need_preprocess == True:\n",
    "                    test_imagette = preprocessing_func(test_imagette_color)\n",
    "                else:\n",
    "                    test_imagette = test_imagette_color\n",
    "            test_imagette = np.reshape(test_imagette,(1,) + test_imagette.shape)\n",
    "            proba = modele.predict(test_imagette)[0]\n",
    "            if proba > threshold:\n",
    "                if from_greyscale:\n",
    "                    imagettes_new.append(test_imagette)\n",
    "                else:\n",
    "                    imagettes_new.append(test_imagette_color)\n",
    "                if display_big:\n",
    "                    ax.scatter(yCoord, xCoord, s=10, c='white', marker='x')\n",
    "                    ax.annotate(str(round(proba[0],2)), xy=(yCoord, xCoord), xytext=(yCoord, xCoord+2))\n",
    "                    fig.canvas.draw()\n",
    "  print(str(nb_test) + ' images testées')\n",
    "  return imagettes_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Image jamais utilisé :\n",
    "#big_image_path = \"../../DATA_MARNIERES/nuit_couleur/Axe3_06h05_14_NC.tif\"\n",
    "#imagettes_color = search_on_big_image(model, big_image_path,\n",
    "#                                      zone = ([6036,10],[6792,734]), threshold = 0.9, display_big = True, stride=5)\n",
    "#imagettes_color = search_on_big_image(model, big_image_path,\n",
    "#                                      zone = ([6186,110],[6342,534]), threshold = 0.9, display_big = True, stride=5)\n",
    "\n",
    "#big_image_path = \"../../DATA_MARNIERES/nuit_couleur/Axe1_04h55_24_NC.tif\"\n",
    "#imagettes_color = search_on_big_image(model, big_image_path,\n",
    "#                                      zone = ([7789,603],[8038,933]), threshold = 0.9, display_big = True, stride=5)\n",
    "\n",
    "big_image_path = \"../../DATA_MARNIERES/nuit_couleur/Axe4_06h10_14_NC.tif\"\n",
    "imagettes_color = search_on_big_image(model, big_image_path,\n",
    "                                      zone = ([5744,230],[6240,1100]), threshold = 0.9, display_big = True, stride=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "len(imagettes_color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_imagettes = len(imagettes_color)\n",
    "if nb_imagettes > 100:\n",
    "    nb_imagettes = 100\n",
    "    imagettes_color_reduce = imagettes_color[:nb_imagettes]\n",
    "else:\n",
    "    imagettes_color_reduce = imagettes_color\n",
    "nb_col = 9\n",
    "nb_row = int(nb_imagettes // nb_col) +1\n",
    "pos = 0\n",
    "plt.figure(figsize=(18, 18))\n",
    "for imagette in imagettes_color_reduce:\n",
    "    pos +=1\n",
    "    plt.subplot(nb_row,nb_col,pos)\n",
    "    plt.imshow(np.moveaxis(imagette,0,2))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find circles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import data, color\n",
    "from skimage.transform import hough_circle\n",
    "from skimage.feature import peak_local_max, canny\n",
    "from skimage.draw import circle_perimeter\n",
    "from skimage.util import img_as_ubyte\n",
    "from skimage.color import rgb2grey"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Calcul pour toute la base de données de la transformée de Hough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(pickle_col_augmented_path, 'rb') as my_pickle:\n",
    "    X, Y = pickle.load(my_pickle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_hough = np.ndarray((X.shape[0],3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, image_col in enumerate(X):\n",
    "    image = rgb2grey(np.moveaxis(image_col,0,2))\n",
    "    edges = canny(image, sigma=1)\n",
    "    hough_res = hough_circle(edges, hough_radii)\n",
    "\n",
    "    centers = []\n",
    "    accums = []\n",
    "    radii = []\n",
    "\n",
    "    for radius, h in zip(hough_radii, hough_res):\n",
    "        # For each radius, extract two circles\n",
    "        num_peaks = 2\n",
    "        peaks = peak_local_max(h, num_peaks=num_peaks)\n",
    "        centers.extend(peaks)\n",
    "        accums.extend(h[peaks[:, 0], peaks[:, 1]])\n",
    "        radii.extend([radius] * num_peaks)\n",
    "\n",
    "    h_peaks = np.sort(accums)[::-1][:3]\n",
    "    h_peaks = np.pad(h_peaks,3-len(h_peaks),mode = 'constant',constant_values=0)[:3]\n",
    "    X_hough[i,:] = h_peaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump([X_hough, Y], open(pickle_hough_val_save_path, 'wb' ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Etude des valeurs h peaks sur la base de données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(pickle_col_augmented_path, 'rb') as my_pickle:\n",
    "    X, Y = pickle.load(my_pickle)\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pos = X[np.where(Y==1)[0]]\n",
    "X_neg = X[np.where(Y==0)[0]]\n",
    "print(\"Il y a {} positifs.\".format(len(X_pos)))\n",
    "print(\"Il y a {} negatifs.\".format(len(X_neg)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import describe\n",
    "hough_radii = np.arange(15, 30, 2)\n",
    "def find_h_peaks_descriptor(DataBaseCol):\n",
    "    h_peaks_tot = []\n",
    "    for image_col in DataBaseCol:\n",
    "        image = rgb2grey(np.moveaxis(image_col,0,2))\n",
    "        edges = canny(image, sigma=1)\n",
    "        hough_res = hough_circle(edges, hough_radii)\n",
    "        \n",
    "        centers = []\n",
    "        accums = []\n",
    "        radii = []\n",
    "\n",
    "        for radius, h in zip(hough_radii, hough_res):\n",
    "            # For each radius, extract two circles\n",
    "            num_peaks = 2\n",
    "            peaks = peak_local_max(h, num_peaks=num_peaks)\n",
    "            centers.extend(peaks)\n",
    "            accums.extend(h[peaks[:, 0], peaks[:, 1]])\n",
    "            radii.extend([radius] * num_peaks)\n",
    "        \n",
    "        h_peaks = np.sort(accums)[::-1][:3]\n",
    "        h_peaks = np.pad(h_peaks,3-len(h_peaks),mode = 'constant',constant_values=0)[:3]\n",
    "        h_peaks_tot.append(h_peaks)\n",
    "    h_peaks_tot = np.array(h_peaks_tot)\n",
    "    print(h_peaks_tot.shape)\n",
    "    print(\"1\")\n",
    "    print(describe(h_peaks_tot[:,0]))\n",
    "    print(\"2\")\n",
    "    print(describe(h_peaks_tot[:,1]))\n",
    "    print(\"3\")\n",
    "    print(describe(h_peaks_tot[:,2]))\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "find_h_peaks_descriptor(X_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "find_h_peaks_descriptor(X_pos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN directement sur image couleur + Hough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(pickle_col_augmented_path, 'rb') as my_pickle:\n",
    "    X, Y = pickle.load(my_pickle)\n",
    "    \n",
    "with open(pickle_hough_val_save_path, 'rb') as my_pickle:\n",
    "    X_hough, _ = pickle.load(my_pickle)\n",
    "\n",
    "indices = np.arange(X.shape[0])\n",
    "X_train, X_test, Y_train, Y_test, idx_train, idx_test = train_test_split(X, Y,indices, test_size=0.1, random_state=42)\n",
    "X_hough_train = X_hough[idx_train,:]\n",
    "X_hough_test = X_hough[idx_test,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "prob_dropout = 0.3\n",
    "first_input = Input(shape=(3,31,31))\n",
    "layer1 = Conv2D(filters = 16, kernel_size = 3, activation ='relu', data_format = \"channels_first\")(first_input)\n",
    "layer1 = Dropout(prob_dropout)(layer1)\n",
    "layer1 = MaxPooling2D(pool_size = (2,2), data_format = \"channels_first\")(layer1)\n",
    "layer1 = Conv2D(filters = 32, kernel_size = 3, activation ='relu', data_format = \"channels_first\")(layer1)\n",
    "layer1 = Dropout(prob_dropout)(layer1)\n",
    "layer1 = MaxPooling2D(pool_size = (2,2), data_format = \"channels_first\")(layer1)\n",
    "layer1 = Conv2D(filters = 64, kernel_size = 3, activation ='sigmoid', data_format = \"channels_first\")(layer1)\n",
    "layer1 = Dropout(prob_dropout)(layer1)\n",
    "layer1 = MaxPooling2D(pool_size = (2,2), data_format = \"channels_first\")(layer1)\n",
    "layer1 = Flatten()(layer1)\n",
    "\n",
    "second_input = Input(shape=(3,))\n",
    "layer2 = Dense(3, activation='relu')(second_input)\n",
    "merge_layer = Concatenate()([layer1, layer2])\n",
    "\n",
    "merge_layer = Dense(64, activation='relu')(merge_layer)\n",
    "merge_layer = Dense(32, activation='relu')(merge_layer)\n",
    "merge_layer = Dense(1, activation='sigmoid')(merge_layer)\n",
    "\n",
    "model = Model(inputs=[first_input, second_input], outputs=merge_layer)\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "prob_dropout = 0.3\n",
    "first_input = Input(shape=(3,31,31))\n",
    "layer1 = Conv2D(filters = 16, kernel_size = 3, activation ='relu', data_format = \"channels_first\")(first_input)\n",
    "layer1 = Dropout(prob_dropout)(layer1)\n",
    "layer1 = MaxPooling2D(pool_size = (2,2), data_format = \"channels_first\")(layer1)\n",
    "layer1 = Conv2D(filters = 32, kernel_size = 3, activation ='relu', data_format = \"channels_first\")(layer1)\n",
    "layer1 = Dropout(prob_dropout)(layer1)\n",
    "layer1 = MaxPooling2D(pool_size = (2,2), data_format = \"channels_first\")(layer1)\n",
    "layer1 = Conv2D(filters = 64, kernel_size = 3, activation ='relu', data_format = \"channels_first\")(layer1)\n",
    "layer1 = Dropout(prob_dropout)(layer1)\n",
    "layer1 = MaxPooling2D(pool_size = (2,2), data_format = \"channels_first\")(layer1)\n",
    "layer1 = Flatten()(layer1)\n",
    "\n",
    "layer1 = Dense(64, activation='relu')(layer1)\n",
    "layer1 = Dense(32, activation='sigmoid')(layer1)\n",
    "\n",
    "second_input = Input(shape=(3,))\n",
    "layer2 = Dense(3, activation='sigmoid')(second_input)\n",
    "\n",
    "merge_layer = Concatenate()([layer1, layer2])\n",
    "\n",
    "merge_layer = Dense(8, activation='relu')(merge_layer)\n",
    "merge_layer = Dense(1, activation='sigmoid')(merge_layer)\n",
    "\n",
    "model = Model(inputs=[first_input, second_input], outputs=merge_layer)\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(model, to_file='../../Images/model_cnn_img_coul_hough.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit([X_train ,X_hough_train], Y_train,\n",
    "          epochs=12,\n",
    "          batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate([X_test, X_hough_test], Y_test)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test CNN image couleur + hough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SIZE_IMAGETTE = 31\n",
    "RAYON_IMAGETTE = int(SIZE_IMAGETTE/2)\n",
    "\n",
    "def preprocessing_func(img_col):\n",
    "    hough_radii = np.arange(15, 30, 2)\n",
    "    image = rgb2grey(np.moveaxis(img_col,0,2))\n",
    "    edges = canny(image, sigma=1)\n",
    "    hough_res = hough_circle(edges, hough_radii)\n",
    "\n",
    "    centers = []\n",
    "    accums = []\n",
    "    radii = []\n",
    "\n",
    "    for radius, h in zip(hough_radii, hough_res):\n",
    "        # For each radius, extract two circles\n",
    "        num_peaks = 2\n",
    "        peaks = peak_local_max(h, num_peaks=num_peaks)\n",
    "        centers.extend(peaks)\n",
    "        accums.extend(h[peaks[:, 0], peaks[:, 1]])\n",
    "        radii.extend([radius] * num_peaks)\n",
    "\n",
    "    h_peaks = np.sort(accums)[::-1][:3]\n",
    "    h_peaks = np.pad(h_peaks,3-len(h_peaks),mode = 'constant',constant_values=0)[:3]\n",
    "    return h_peaks\n",
    "\n",
    "def search_on_big_image(modele,image_path, need_preprocess = False, stride = 25, from_greyscale = False, zone = None, display_big = False, threshold = 0.5):\n",
    "  #On fait glisser une fenêtre sur toute l'image\n",
    "  imagettes_new = []\n",
    "  tif_file = TIFF.open(image_path, mode='r')\n",
    "  big_image = tif_file.read_image()\n",
    "  if zone:\n",
    "    pt1 = zone[0]\n",
    "    pt2 = zone[1]\n",
    "    if from_greyscale:\n",
    "        big_image = big_image[pt1[0]:pt2[0]+1,pt1[1]:pt2[1]+1]\n",
    "    else:\n",
    "        big_image = big_image[:,pt1[0]:pt2[0]+1,pt1[1]:pt2[1]+1]\n",
    "  big_shape = big_image.shape\n",
    "  print(\"shape big image :\",big_shape)\n",
    "  if display_big:\n",
    "    plt.ion()\n",
    "    fig = plt.figure(figsize=(18, 18))\n",
    "    ax = fig.add_subplot(111)\n",
    "    if from_greyscale:\n",
    "        ax.imshow(big_image, cmap='gray')\n",
    "        plt.show()\n",
    "    else:\n",
    "        ax.imshow(np.moveaxis(big_image,0,2))\n",
    "        fig.canvas.draw()\n",
    "  nb_test = 0\n",
    "  for xCoord in np.arange(start = SIZE_IMAGETTE, stop = big_shape[1] - SIZE_IMAGETTE, step = stride):\n",
    "      for yCoord in np.arange(start = SIZE_IMAGETTE, stop = big_shape[2] - SIZE_IMAGETTE, step = stride):\n",
    "            nb_test +=1\n",
    "            if from_greyscale:\n",
    "                test_imagette = big_image[xCoord-RAYON_IMAGETTE : xCoord+RAYON_IMAGETTE+1, yCoord-RAYON_IMAGETTE : yCoord+RAYON_IMAGETTE+1]                    \n",
    "            else:\n",
    "                test_imagette_color = big_image[:, xCoord-RAYON_IMAGETTE : xCoord+RAYON_IMAGETTE+1, yCoord-RAYON_IMAGETTE : yCoord+RAYON_IMAGETTE+1]\n",
    "                #if grey_modele:\n",
    "                #   test_imagette = RGBToGreyscale(test_imagette_color)\n",
    "                if need_preprocess == True:\n",
    "                    h_peaks = preprocessing_func(test_imagette_color)\n",
    "                    test_imagette = test_imagette_color\n",
    "                else:\n",
    "                    test_imagette = test_imagette_color\n",
    "            test_imagette = np.reshape(test_imagette,(1,) + test_imagette.shape)\n",
    "            h_peaks = np.reshape(h_peaks,(1,) + h_peaks.shape)\n",
    "            proba = modele.predict([test_imagette, h_peaks])[0]\n",
    "            if proba > threshold:\n",
    "                if from_greyscale:\n",
    "                    imagettes_new.append(test_imagette)\n",
    "                else:\n",
    "                    imagettes_new.append(test_imagette_color)\n",
    "                if display_big:\n",
    "                    ax.scatter(yCoord, xCoord, s=10, c='white', marker='x')\n",
    "                    ax.annotate(str(round(proba[0],2)), xy=(yCoord, xCoord), xytext=(yCoord, xCoord+2))\n",
    "                    fig.canvas.draw()\n",
    "  print(str(nb_test) + ' images testées')\n",
    "  return imagettes_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Image jamais utilisé :\n",
    "big_image_path = \"../../DATA_MARNIERES/nuit_couleur/Axe3_06h05_14_NC.tif\"\n",
    "#imagettes_color = search_on_big_image(model, big_image_path, need_preprocess = True,\n",
    "#                                      zone = ([6036,10],[6792,734]), threshold = 0.9, display_big = True, stride=5)\n",
    "#imagettes_color = search_on_big_image(model, big_image_path, need_preprocess = True,\n",
    "#                                      zone = ([6186,110],[6342,534]), threshold = 0.9, display_big = True, stride=5)\n",
    "\n",
    "#big_image_path = \"../../DATA_MARNIERES/nuit_couleur/Axe1_04h55_24_NC.tif\"\n",
    "#imagettes_color = search_on_big_image(model, big_image_path, need_preprocess = True,\n",
    "#                                      zone = ([7789,603],[8038,933]), threshold = 0.9, display_big = True, stride=5)\n",
    "\n",
    "big_image_path = \"../../DATA_MARNIERES/nuit_couleur/Axe4_06h10_14_NC.tif\"\n",
    "imagettes_color = search_on_big_image(model, big_image_path,need_preprocess = True,\n",
    "                                      zone = ([5744,230],[6240,1100]), threshold = 0.9, display_big = True, stride=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(imagettes_color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_imagettes = len(imagettes_color)\n",
    "if nb_imagettes > 100:\n",
    "    nb_imagettes = 100\n",
    "    imagettes_color_reduce = imagettes_color[:nb_imagettes]\n",
    "else:\n",
    "    imagettes_color_reduce = imagettes_color\n",
    "nb_col = 9\n",
    "nb_row = int(nb_imagettes // nb_col) +1\n",
    "pos = 0\n",
    "plt.figure(figsize=(18, 18))\n",
    "for imagette in imagettes_color_reduce:\n",
    "    pos +=1\n",
    "    plt.subplot(nb_row,nb_col,pos)\n",
    "    plt.imshow(np.moveaxis(imagette,0,2))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### matrice hessian ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.feature import hessian_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calcul sur toute la base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(pickle_col_augmented_path, 'rb') as my_pickle:\n",
    "    X, Y = pickle.load(my_pickle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_hes = np.ndarray((X.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, image_col in enumerate(X):\n",
    "    image = rgb2grey(np.moveaxis(image_col,0,2))\n",
    "    X_hes[i] = np.array(hessian_matrix(image,order=\"rc\", sigma=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump([X_hes, Y], open(pickle_hes_val_save_path, 'wb' ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN sur hessian value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(pickle_hes_val_save_path, 'rb') as my_pickle:\n",
    "    X, Y = pickle.load(my_pickle)\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_dropout = 0.3\n",
    "model = Sequential()\n",
    "model.add(Conv2D(filters = 16, kernel_size = 3, activation ='relu', data_format = \"channels_first\", input_shape = (3,31,31)))\n",
    "model.add(Dropout(prob_dropout))\n",
    "model.add(MaxPooling2D(pool_size = (2,2), data_format = \"channels_first\"))\n",
    "model.add(Conv2D(filters = 32, kernel_size = 3, activation ='relu', data_format = \"channels_first\"))\n",
    "model.add(Dropout(prob_dropout))\n",
    "model.add(MaxPooling2D(pool_size = (2,2), data_format = \"channels_first\"))\n",
    "model.add(Conv2D(filters = 64, kernel_size = 3, activation ='relu', data_format = \"channels_first\"))\n",
    "model.add(Dropout(prob_dropout))\n",
    "model.add(MaxPooling2D(pool_size = (2,2), data_format = \"channels_first\"))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.fit(X_train, Y_train,\n",
    "          epochs=15,\n",
    "          batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(X_test, Y_test)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TEST CNN sur hessian value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SIZE_IMAGETTE = 31\n",
    "RAYON_IMAGETTE = int(SIZE_IMAGETTE/2)\n",
    "\n",
    "def preprocessing_func(image_col):\n",
    "    image = rgb2grey(np.moveaxis(image_col,0,2))\n",
    "    return np.array(hessian_matrix(image,order=\"rc\", sigma=1))\n",
    "\n",
    "def search_on_big_image(modele,image_path, need_preprocess = False, stride = 25, from_greyscale = False, zone = None, display_big = False, threshold = 0.5):\n",
    "  #On fait glisser une fenêtre sur toute l'image\n",
    "  imagettes_new = []\n",
    "  tif_file = TIFF.open(image_path, mode='r')\n",
    "  big_image = tif_file.read_image()\n",
    "  if zone:\n",
    "    pt1 = zone[0]\n",
    "    pt2 = zone[1]\n",
    "    if from_greyscale:\n",
    "        big_image = big_image[pt1[0]:pt2[0]+1,pt1[1]:pt2[1]+1]\n",
    "    else:\n",
    "        big_image = big_image[:,pt1[0]:pt2[0]+1,pt1[1]:pt2[1]+1]\n",
    "  big_shape = big_image.shape\n",
    "  print(\"shape big image :\",big_shape)\n",
    "  if display_big:\n",
    "    plt.ion()\n",
    "    fig = plt.figure(figsize=(18, 18))\n",
    "    ax = fig.add_subplot(111)\n",
    "    if from_greyscale:\n",
    "        ax.imshow(big_image, cmap='gray')\n",
    "        plt.show()\n",
    "    else:\n",
    "        ax.imshow(np.moveaxis(big_image,0,2))\n",
    "        fig.canvas.draw()\n",
    "  nb_test = 0\n",
    "  for xCoord in np.arange(start = SIZE_IMAGETTE, stop = big_shape[1] - SIZE_IMAGETTE, step = stride):\n",
    "      for yCoord in np.arange(start = SIZE_IMAGETTE, stop = big_shape[2] - SIZE_IMAGETTE, step = stride):\n",
    "            nb_test +=1\n",
    "            if from_greyscale:\n",
    "                test_imagette = big_image[xCoord-RAYON_IMAGETTE : xCoord+RAYON_IMAGETTE+1, yCoord-RAYON_IMAGETTE : yCoord+RAYON_IMAGETTE+1]                    \n",
    "            else:\n",
    "                test_imagette_color = big_image[:, xCoord-RAYON_IMAGETTE : xCoord+RAYON_IMAGETTE+1, yCoord-RAYON_IMAGETTE : yCoord+RAYON_IMAGETTE+1]\n",
    "                #if grey_modele:\n",
    "                #   test_imagette = RGBToGreyscale(test_imagette_color)\n",
    "                if need_preprocess == True:\n",
    "                    test_imagette = preprocessing_func(test_imagette_color)\n",
    "                else:\n",
    "                    test_imagette = test_imagette_color\n",
    "            test_imagette = np.reshape(test_imagette,(1,) + test_imagette.shape)\n",
    "            proba = modele.predict(test_imagette)[0]\n",
    "            if proba > threshold:\n",
    "                if from_greyscale:\n",
    "                    imagettes_new.append(test_imagette)\n",
    "                else:\n",
    "                    imagettes_new.append(test_imagette_color)\n",
    "                if display_big:\n",
    "                    ax.scatter(yCoord, xCoord, s=10, c='white', marker='x')\n",
    "                    ax.annotate(str(round(proba[0],2)), xy=(yCoord, xCoord), xytext=(yCoord, xCoord+2))\n",
    "                    fig.canvas.draw()\n",
    "  print(str(nb_test) + ' images testées')\n",
    "  return imagettes_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Image jamais utilisé :\n",
    "big_image_path = \"../../DATA_MARNIERES/nuit_couleur/Axe3_06h05_14_NC.tif\"\n",
    "imagettes_color = search_on_big_image(model, big_image_path,need_preprocess=True,\n",
    "                                      zone = ([6036,10],[6792,734]), threshold = 0.8, display_big = True, stride=5)\n",
    "#imagettes_color = search_on_big_image(model, big_image_path, need_preprocess=True,\n",
    "#                                      zone = ([6186,110],[6342,534]), threshold = 0.7, display_big = True, stride=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "len(imagettes_color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_imagettes = len(imagettes_color)\n",
    "if nb_imagettes > 100:\n",
    "    nb_imagettes = 100\n",
    "    imagettes_color_reduce = imagettes_color[:nb_imagettes]\n",
    "else:\n",
    "    imagettes_color_reduce = imagettes_color\n",
    "nb_col = 9\n",
    "nb_row = int(nb_imagettes // nb_col) +1\n",
    "pos = 0\n",
    "plt.figure(figsize=(18, 18))\n",
    "for imagette in imagettes_color_reduce:\n",
    "    pos +=1\n",
    "    plt.subplot(nb_row,nb_col,pos)\n",
    "    plt.imshow(np.moveaxis(imagette,0,2))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN sur hessian value + hough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(pickle_hes_val_save_path, 'rb') as my_pickle:\n",
    "    X_hes, Y = pickle.load(my_pickle)\n",
    "    \n",
    "with open(pickle_hough_val_save_path, 'rb') as my_pickle:\n",
    "    X_hough, _ = pickle.load(my_pickle)\n",
    "\n",
    "indices = np.arange(X_hes.shape[0])\n",
    "X_train, X_test, Y_train, Y_test, idx_train, idx_test = train_test_split(X_hes, Y, indices, test_size=0.1, random_state=42)\n",
    "X_hough_train = X_hough[idx_train,:]\n",
    "X_hough_test = X_hough[idx_test,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_dropout = 0.3\n",
    "first_input = Input(shape=(3,31,31))\n",
    "layer1 = Conv2D(filters = 16, kernel_size = 3, activation ='relu', data_format = \"channels_first\")(first_input)\n",
    "layer1 = Dropout(prob_dropout)(layer1)\n",
    "layer1 = MaxPooling2D(pool_size = (2,2), data_format = \"channels_first\")(layer1)\n",
    "layer1 = Conv2D(filters = 32, kernel_size = 3, activation ='relu', data_format = \"channels_first\")(layer1)\n",
    "layer1 = Dropout(prob_dropout)(layer1)\n",
    "layer1 = MaxPooling2D(pool_size = (2,2), data_format = \"channels_first\")(layer1)\n",
    "layer1 = Conv2D(filters = 64, kernel_size = 3, activation ='relu', data_format = \"channels_first\")(layer1)\n",
    "layer1 = Dropout(prob_dropout)(layer1)\n",
    "layer1 = MaxPooling2D(pool_size = (2,2), data_format = \"channels_first\")(layer1)\n",
    "layer1 = Flatten()(layer1)\n",
    "\n",
    "layer1 = Dense(64, activation='relu')(layer1)\n",
    "layer1 = Dense(32, activation='sigmoid')(layer1)\n",
    "\n",
    "second_input = Input(shape=(3,))\n",
    "layer2 = Dense(3, activation='sigmoid')(second_input)\n",
    "\n",
    "merge_layer = Concatenate()([layer1, layer2])\n",
    "\n",
    "merge_layer = Dense(8, activation='relu')(merge_layer)\n",
    "merge_layer = Dense(1, activation='sigmoid')(merge_layer)\n",
    "\n",
    "model = Model(inputs=[first_input, second_input], outputs=merge_layer)\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit([X_train ,X_hough_train], Y_train,\n",
    "          epochs=2,\n",
    "          batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate([X_test, X_hough_test], Y_test)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test CNN hessian value + hough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SIZE_IMAGETTE = 31\n",
    "RAYON_IMAGETTE = int(SIZE_IMAGETTE/2)\n",
    "\n",
    "def preprocessing_hough_func(img_col):\n",
    "    hough_radii = np.arange(15, 30, 2)\n",
    "    image = rgb2grey(np.moveaxis(img_col,0,2))\n",
    "    edges = canny(image, sigma=1)\n",
    "    hough_res = hough_circle(edges, hough_radii)\n",
    "\n",
    "    centers = []\n",
    "    accums = []\n",
    "    radii = []\n",
    "\n",
    "    for radius, h in zip(hough_radii, hough_res):\n",
    "        # For each radius, extract two circles\n",
    "        num_peaks = 2\n",
    "        peaks = peak_local_max(h, num_peaks=num_peaks)\n",
    "        centers.extend(peaks)\n",
    "        accums.extend(h[peaks[:, 0], peaks[:, 1]])\n",
    "        radii.extend([radius] * num_peaks)\n",
    "\n",
    "    h_peaks = np.sort(accums)[::-1][:3]\n",
    "    h_peaks = np.pad(h_peaks,3-len(h_peaks),mode = 'constant',constant_values=0)[:3]\n",
    "    return h_peaks\n",
    "\n",
    "def preprocessing_hes_func(image_col):\n",
    "    image = rgb2grey(np.moveaxis(image_col,0,2))\n",
    "    return np.array(hessian_matrix(image,order=\"rc\", sigma=1))\n",
    "\n",
    "def search_on_big_image(modele,image_path, need_preprocess = False, stride = 25, from_greyscale = False, zone = None, display_big = False, threshold = 0.5):\n",
    "  #On fait glisser une fenêtre sur toute l'image\n",
    "  imagettes_new = []\n",
    "  tif_file = TIFF.open(image_path, mode='r')\n",
    "  big_image = tif_file.read_image()\n",
    "  if zone:\n",
    "    pt1 = zone[0]\n",
    "    pt2 = zone[1]\n",
    "    if from_greyscale:\n",
    "        big_image = big_image[pt1[0]:pt2[0]+1,pt1[1]:pt2[1]+1]\n",
    "    else:\n",
    "        big_image = big_image[:,pt1[0]:pt2[0]+1,pt1[1]:pt2[1]+1]\n",
    "  big_shape = big_image.shape\n",
    "  print(\"shape big image :\",big_shape)\n",
    "  if display_big:\n",
    "    plt.ion()\n",
    "    fig = plt.figure(figsize=(18, 18))\n",
    "    ax = fig.add_subplot(111)\n",
    "    if from_greyscale:\n",
    "        ax.imshow(big_image, cmap='gray')\n",
    "        plt.show()\n",
    "    else:\n",
    "        ax.imshow(np.moveaxis(big_image,0,2))\n",
    "        fig.canvas.draw()\n",
    "  nb_test = 0\n",
    "  for xCoord in np.arange(start = SIZE_IMAGETTE, stop = big_shape[1] - SIZE_IMAGETTE, step = stride):\n",
    "      for yCoord in np.arange(start = SIZE_IMAGETTE, stop = big_shape[2] - SIZE_IMAGETTE, step = stride):\n",
    "            nb_test +=1\n",
    "            if from_greyscale:\n",
    "                test_imagette = big_image[xCoord-RAYON_IMAGETTE : xCoord+RAYON_IMAGETTE+1, yCoord-RAYON_IMAGETTE : yCoord+RAYON_IMAGETTE+1]                    \n",
    "            else:\n",
    "                test_imagette_color = big_image[:, xCoord-RAYON_IMAGETTE : xCoord+RAYON_IMAGETTE+1, yCoord-RAYON_IMAGETTE : yCoord+RAYON_IMAGETTE+1]\n",
    "                #if grey_modele:\n",
    "                #   test_imagette = RGBToGreyscale(test_imagette_color)\n",
    "                if need_preprocess == True:\n",
    "                    h_peaks = preprocessing_hough_func(test_imagette_color)\n",
    "                    test_hes = preprocessing_hes_func(test_imagette_color)\n",
    "                else:\n",
    "                    test_imagette = test_imagette_color\n",
    "            test_hes = np.reshape(test_hes,(1,) + test_hes.shape)\n",
    "            h_peaks = np.reshape(h_peaks,(1,) + h_peaks.shape)\n",
    "            proba = modele.predict([test_hes, h_peaks])[0]\n",
    "            if proba > threshold:\n",
    "                if from_greyscale:\n",
    "                    imagettes_new.append(test_imagette)\n",
    "                else:\n",
    "                    imagettes_new.append(test_imagette_color)\n",
    "                if display_big:\n",
    "                    ax.scatter(yCoord, xCoord, s=10, c='white', marker='x')\n",
    "                    ax.annotate(str(round(proba[0],2)), xy=(yCoord, xCoord), xytext=(yCoord, xCoord+2))\n",
    "                    fig.canvas.draw()\n",
    "  print(str(nb_test) + ' images testées')\n",
    "  return imagettes_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Image jamais utilisé :\n",
    "big_image_path = \"../../DATA_MARNIERES/nuit_couleur/Axe3_06h05_14_NC.tif\"\n",
    "#imagettes_color = search_on_big_image(model, big_image_path, need_preprocess = True,\n",
    "#                                      zone = ([6036,10],[6792,734]), threshold = 0.9, display_big = True, stride=5)\n",
    "imagettes_color = search_on_big_image(model, big_image_path, need_preprocess = True,\n",
    "                                     zone = ([6186,110],[6342,534]), threshold = 0.9, display_big = True, stride=5)\n",
    "\n",
    "#big_image_path = \"../../DATA_MARNIERES/nuit_couleur/Axe1_04h55_24_NC.tif\"\n",
    "#imagettes_color = search_on_big_image(model, big_image_path, need_preprocess = True,\n",
    "#                                      zone = ([7789,603],[8038,933]), threshold = 0.9, display_big = True, stride=5)\n",
    "\n",
    "#big_image_path = \"../../DATA_MARNIERES/nuit_couleur/Axe4_06h10_14_NC.tif\"\n",
    "#imagettes_color = search_on_big_image(model, big_image_path,need_preprocess = True,\n",
    "#                                      zone = ([5744,230],[6240,1100]), threshold = 0.9, display_big = True, stride=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(imagettes_color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_imagettes = len(imagettes_color)\n",
    "if nb_imagettes > 100:\n",
    "    nb_imagettes = 100\n",
    "    imagettes_color_reduce = imagettes_color[:nb_imagettes]\n",
    "else:\n",
    "    imagettes_color_reduce = imagettes_color\n",
    "nb_col = 9\n",
    "nb_row = int(nb_imagettes // nb_col) +1\n",
    "pos = 0\n",
    "plt.figure(figsize=(18, 18))\n",
    "for imagette in imagettes_color_reduce:\n",
    "    pos +=1\n",
    "    plt.subplot(nb_row,nb_col,pos)\n",
    "    plt.imshow(np.moveaxis(imagette,0,2))\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
