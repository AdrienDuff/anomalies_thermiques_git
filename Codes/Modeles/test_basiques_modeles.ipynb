{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Import des librairies python et définitions de constantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "#%matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from libtiff import TIFF\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.mixture import BayesianGaussianMixture\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "#import ImageFilter\n",
    "\n",
    "#from search_on_big_images import search_on_big_image\n",
    "#import search_on_big_images\n",
    "pickle_save_path = \"../../Data/\"\n",
    "pickle_col_augmented_path = \"../../Data/col_augmented.pickle\"\n",
    "pickle_col_not_augmented_path = \"../../Data/col_not_augmented.pickle\"\n",
    "pickle_grey_augmented_path = \"../../Data/grey_augmented.pickle\"\n",
    "pickle_grey_not_augmented_path = \"../../Data/grey_not_augmented.pickle\"\n",
    "pickle_hough_val_save_path = \"../../Data/hough_val.pickle\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Import des données\n",
    "On essaie d'abord avec les données les plus simples. En Greyscale et sans augmentation des données."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(pickle_grey_augmented_path, 'rb') as my_pickle:\n",
    "    X, Y = pickle.load(my_pickle)\n",
    "X = X.reshape((X.shape[0],-1))\n",
    "X_norm = normalize(X.reshape((X.shape[0],-1))) #we normalize the data\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training score : 1.0\n",
      "Test score : 0.9356617647058824\n",
      "\n",
      "Matrice de confusion training :\n",
      "[[2461    0]\n",
      " [   0 2434]]\n",
      "\n",
      "Matrice de confusion test :\n",
      "[[252  17]\n",
      " [ 18 257]]\n"
     ]
    }
   ],
   "source": [
    "# Construction of the Classifier TREE\n",
    "decision_tree = DecisionTreeClassifier()\n",
    "#Learn the classifier\n",
    "decision_tree.fit(X_train, Y_train)\n",
    "#Compute the score\n",
    "train_score = decision_tree.score(X_train, Y_train)\n",
    "test_score = decision_tree.score(X_test, Y_test)\n",
    "print(\"Training score : \" + str(train_score))\n",
    "print(\"Test score : \" + str(test_score))\n",
    "print(\"\\nMatrice de confusion training :\")\n",
    "print(confusion_matrix(Y_train, decision_tree.predict(X_train)))\n",
    "\n",
    "print(\"\\nMatrice de confusion test :\")\n",
    "print(confusion_matrix(Y_test, decision_tree.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On fait du sur-apprentissage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Les k plus proches voisins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training score : 0.982635342185904\n",
      "Test score : 0.9577205882352942\n",
      "\n",
      "Matrice de confusion training :\n",
      "[[2443   18]\n",
      " [  67 2367]]\n",
      "\n",
      "Matrice de confusion test :\n",
      "[[265   4]\n",
      " [ 19 256]]\n"
     ]
    }
   ],
   "source": [
    "#Now we take a stable classifier\n",
    "neighbors_estimator = KNeighborsClassifier(n_neighbors=3)\n",
    "#Learn the classifier\n",
    "neighbors_estimator.fit(X_train, Y_train)\n",
    "#Compute the score\n",
    "train_score = neighbors_estimator.score(X_train, Y_train)\n",
    "test_score = neighbors_estimator.score(X_test, Y_test)\n",
    "print(\"Training score : \" + str(train_score))\n",
    "print(\"Test score : \" + str(test_score))\n",
    "print(\"\\nMatrice de confusion training :\")\n",
    "print(confusion_matrix(Y_train, neighbors_estimator.predict(X_train)))\n",
    "\n",
    "print(\"\\nMatrice de confusion test :\")\n",
    "print(confusion_matrix(Y_test, neighbors_estimator.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training score : 1.0\n",
      "Test score : 0.9852941176470589\n",
      "\n",
      "Matrice de confusion training :\n",
      "[[2461    0]\n",
      " [   0 2434]]\n",
      "\n",
      "Matrice de confusion test :\n",
      "[[261   8]\n",
      " [  0 275]]\n"
     ]
    }
   ],
   "source": [
    "randomForest = RandomForestClassifier(n_estimators=200)\n",
    "randomForest.fit(X_train, Y_train)\n",
    "train_score = randomForest.score(X_train, Y_train)\n",
    "test_score = randomForest.score(X_test, Y_test)\n",
    "print(\"Training score : \" + str(train_score))\n",
    "print(\"Test score : \" + str(test_score))\n",
    "print(\"\\nMatrice de confusion training :\")\n",
    "print(confusion_matrix(Y_train, randomForest.predict(X_train)))\n",
    "\n",
    "print(\"\\nMatrice de confusion test :\")\n",
    "print(confusion_matrix(Y_test, randomForest.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ACP puis KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reduced_X = PCA(n_components=2).fit_transform(X.reshape((X.shape[0],-1)))\n",
    "acp_modele = PCA(n_components=3)\n",
    "reduced_X = acp_modele.fit_transform(X_norm)\n",
    "plt.plot(reduced_X[np.where(Y==1)[0]][:, 0], reduced_X[np.where(Y==1)[0]][:, 1], 'k.', markersize=8, color = \"red\")\n",
    "plt.plot(reduced_X[np.where(Y==0)[0]][:, 0], reduced_X[np.where(Y==0)[0]][:, 1], 'k.', markersize=3, color = \"blue\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training score : 1.0\n",
      "\n",
      "Matrice de confusion training :\n",
      "[[2730    0]\n",
      " [   0 2709]]\n"
     ]
    }
   ],
   "source": [
    "neighbors_estimator = KNeighborsClassifier(n_neighbors=1)\n",
    "#Learn the classifier\n",
    "neighbors_estimator.fit(reduced_X, Y)\n",
    "#Compute the score\n",
    "train_score = neighbors_estimator.score(reduced_X, Y)\n",
    "print(\"Training score : \" + str(train_score))\n",
    "print(\"\\nMatrice de confusion training :\")\n",
    "print(confusion_matrix(Y, neighbors_estimator.predict(reduced_X)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "SIZE_IMAGETTE = 31\n",
    "RAYON_IMAGETTE = int(SIZE_IMAGETTE/2)\n",
    "\n",
    "def weightedAverage(pixel):\n",
    "    return 0.299*pixel[0] + 0.587*pixel[1] + 0.114*pixel[2]\n",
    "\n",
    "def RGBToGreyscale(image):\n",
    "  grey_image = np.zeros((image.shape[1], image.shape[2]), dtype = np.uint8) # init 2D numpy array\n",
    "  # get row number\n",
    "  for rownum in range(image.shape[1]):\n",
    "     for colnum in range(image.shape[2]):\n",
    "        grey_image[rownum,colnum] = int(weightedAverage(image[:,rownum,colnum]))\n",
    "  return grey_image\n",
    "\n",
    "def search_on_big_image(acp_modele,modele,image_path, stride = 20, grey_modele = True, from_greyscale = False, size_max_x = None, size_max_y = None):\n",
    "  #On fait glisser une fenêtre sur toute l'image\n",
    "  imagettes_new = []\n",
    "  tif_file = TIFF.open(image_path, mode='r')\n",
    "  big_image = tif_file.read_image()\n",
    "  if size_max_x:\n",
    "      big_image = big_image[:,1000:1000+size_max_x,:]\n",
    "  if size_max_y:\n",
    "      big_image = big_image[:,:,1000:1000+size_max_y]\n",
    "  big_shape = big_image.shape\n",
    "  print(big_shape)\n",
    "  for xCoord in np.arange(start = SIZE_IMAGETTE, stop = big_shape[1] - SIZE_IMAGETTE, step = stride):\n",
    "      for yCoord in np.arange(start = SIZE_IMAGETTE, stop = big_shape[2] - SIZE_IMAGETTE, step = stride):\n",
    "            if from_greyscale:\n",
    "                test_imagette = big_image[xCoord-RAYON_IMAGETTE : xCoord+RAYON_IMAGETTE+1, yCoord-RAYON_IMAGETTE : yCoord+RAYON_IMAGETTE+1]                    \n",
    "            else:\n",
    "                test_imagette_color = big_image[:, xCoord-RAYON_IMAGETTE : xCoord+RAYON_IMAGETTE+1, yCoord-RAYON_IMAGETTE : yCoord+RAYON_IMAGETTE+1]\n",
    "                if grey_modele:\n",
    "                    test_imagette = RGBToGreyscale(test_imagette_color)\n",
    "            test_imagette = test_imagette.reshape((1,-1))\n",
    "            if modele.predict(acp_modele.transform(test_imagette))[0] == 1:\n",
    "                if from_greyscale:\n",
    "                    imagettes_new.append(test_imagette)\n",
    "                else:\n",
    "                    imagettes_new.append(test_imagette_color)\n",
    "  return imagettes_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 800, 800)\n"
     ]
    }
   ],
   "source": [
    "#Image jamais utilisé :\n",
    "big_image_path = \"../../DATA_MARNIERES/DAT_marnieres_epreville_270799_jour/27_07_99/jour/calibre/TIF/Axe2_16h47_24_C.tif\"\n",
    "imagettes_color = search_on_big_image(acp_modele,neighbors_estimator,big_image_path, size_max_x = 800, size_max_y = 800)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "#### Test sur grande image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training score : 0.9930795847750865\n"
     ]
    }
   ],
   "source": [
    "neighbors_estimator = KNeighborsClassifier(n_neighbors=3)\n",
    "#Learn the classifier\n",
    "neighbors_estimator.fit(X, Y)\n",
    "train_score = randomForest.score(X, Y)\n",
    "print(\"Training score : \" + str(train_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "SIZE_IMAGETTE = 31\n",
    "RAYON_IMAGETTE = int(SIZE_IMAGETTE/2)\n",
    "\n",
    "def weightedAverage(pixel):\n",
    "    return 0.299*pixel[0] + 0.587*pixel[1] + 0.114*pixel[2]\n",
    "\n",
    "def RGBToGreyscale(image):\n",
    "  grey_image = np.zeros((image.shape[1], image.shape[2]), dtype = np.uint8) # init 2D numpy array\n",
    "  # get row number\n",
    "  for rownum in range(image.shape[1]):\n",
    "     for colnum in range(image.shape[2]):\n",
    "        grey_image[rownum,colnum] = int(weightedAverage(image[:,rownum,colnum]))\n",
    "  return grey_image\n",
    "\n",
    "def search_on_big_image(modele,image_path, stride = 20, grey_modele = True, from_greyscale = False, size_max_x = None, size_max_y = None):\n",
    "  #On fait glisser une fenêtre sur toute l'image\n",
    "  imagettes_new = []\n",
    "  tif_file = TIFF.open(image_path, mode='r')\n",
    "  big_image = tif_file.read_image()\n",
    "  if size_max_x:\n",
    "      big_image = big_image[:,1000:1000+size_max_x,:]\n",
    "  if size_max_y:\n",
    "      big_image = big_image[:,:,1000:1000+size_max_y]\n",
    "  big_shape = big_image.shape\n",
    "  print(big_shape)\n",
    "  for xCoord in np.arange(start = SIZE_IMAGETTE, stop = big_shape[1] - SIZE_IMAGETTE, step = stride):\n",
    "      for yCoord in np.arange(start = SIZE_IMAGETTE, stop = big_shape[2] - SIZE_IMAGETTE, step = stride):\n",
    "            if from_greyscale:\n",
    "                test_imagette = big_image[xCoord-RAYON_IMAGETTE : xCoord+RAYON_IMAGETTE+1, yCoord-RAYON_IMAGETTE : yCoord+RAYON_IMAGETTE+1]                    \n",
    "            else:\n",
    "                test_imagette_color = big_image[:, xCoord-RAYON_IMAGETTE : xCoord+RAYON_IMAGETTE+1, yCoord-RAYON_IMAGETTE : yCoord+RAYON_IMAGETTE+1]\n",
    "                if grey_modele:\n",
    "                    test_imagette = RGBToGreyscale(test_imagette_color)\n",
    "            test_imagette = test_imagette.reshape((1,-1))\n",
    "            if modele.predict(test_imagette)[0] == 1:\n",
    "                if from_greyscale:\n",
    "                    imagettes_new.append(test_imagette)\n",
    "                else:\n",
    "                    imagettes_new.append(test_imagette_color)\n",
    "  return imagettes_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 1000, 1000)\n"
     ]
    }
   ],
   "source": [
    "#Image jamais utilisé :\n",
    "big_image_path = \"../../DATA_MARNIERES/DAT_marnieres_epreville_270799_jour/27_07_99/jour/calibre/TIF/Axe2_16h47_24_C.tif\"\n",
    "imagettes_color = search_on_big_image(randomForest,big_image_path, size_max_x = 1000, size_max_y = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59\n"
     ]
    }
   ],
   "source": [
    "print(len(imagettes_color))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_imagettes = len(imagettes_color)\n",
    "if nb_imagettes > 100:\n",
    "    nb_imagettes = 100\n",
    "    imagettes_color_reduce = imagettes_color[:nb_imagettes]\n",
    "else:\n",
    "    imagettes_color_reduce = imagettes_color\n",
    "nb_col = 9\n",
    "nb_row = int(nb_imagettes // nb_col) +1\n",
    "pos = 0\n",
    "plt.figure(figsize=(18, 18))\n",
    "for imagette in imagettes_color_reduce:\n",
    "    pos +=1\n",
    "    plt.subplot(nb_row,nb_col,pos)\n",
    "    plt.imshow(np.moveaxis(imagette,0,2))\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
